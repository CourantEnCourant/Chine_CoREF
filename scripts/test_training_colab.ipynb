{
 "cells": [
  {
   "cell_type": "code",
   "id": "E9bPpsGJ9LB9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1096,
     "status": "ok",
     "timestamp": 1721222431277,
     "user": {
      "displayName": "Weiqi ZHANG",
      "userId": "02633163666874873570"
     },
     "user_tz": -120
    },
    "id": "E9bPpsGJ9LB9",
    "outputId": "966be7c3-0b53-47f7-9986-8005daa49a54",
    "ExecuteTime": {
     "end_time": "2024-07-17T12:52:43.082032Z",
     "start_time": "2024-07-17T12:52:43.048216Z"
    }
   },
   "source": [
    "print('On colab')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "On colab\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install datasets transformers evaluate\n",
    "!pip install accelerate -U"
   ],
   "metadata": {
    "id": "DbXtZnFn2hrS"
   },
   "id": "DbXtZnFn2hrS",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "h5WRXAyy9PMY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5WRXAyy9PMY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1721222448619,
     "user_tz": -120,
     "elapsed": 2853,
     "user": {
      "displayName": "Weiqi ZHANG",
      "userId": "02633163666874873570"
     }
    },
    "outputId": "840e1b1d-5613-4626-b8d0-3e6512021111"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/Othercomputers/MacbookAir/coref_personal/scripts')"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 16034,
     "status": "ok",
     "timestamp": 1721222472888,
     "user": {
      "displayName": "Weiqi ZHANG",
      "userId": "02633163666874873570"
     },
     "user_tz": -120
    },
    "id": "initial_id",
    "outputId": "ac992f18-3fa5-4557-cc03-90387418d3ef",
    "ExecuteTime": {
     "end_time": "2024-07-17T13:11:50.618774Z",
     "start_time": "2024-07-17T13:11:15.142273Z"
    }
   },
   "source": [
    "# Prepare dataset, tokenizer and model, transfer model to GPU\n",
    "from datasets import Dataset\n",
    "from create_training import split_train_dev_test\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "import torch\n",
    "\n",
    "test_set = Dataset.from_parquet('../data/clean/test.parquet')\n",
    "train, dev, test = split_train_dev_test(test_set)\n",
    "\n",
    "checkpoint = 'hfl/chinese-roberta-wwm-ext'\n",
    "cache_dir = '../src/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f'device: {device}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "c581e0d7c73b2ae1",
   "metadata": {
    "id": "c581e0d7c73b2ae1",
    "ExecuteTime": {
     "end_time": "2024-07-17T12:55:40.019090Z",
     "start_time": "2024-07-17T12:55:09.549799Z"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1721222481382,
     "user_tz": -120,
     "elapsed": 1032,
     "user": {
      "displayName": "Weiqi ZHANG",
      "userId": "02633163666874873570"
     }
    }
   },
   "source": [
    "# Prepare the tokenizer\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"tweets\"], truncation=True, max_length=512)\n",
    "\n",
    "tokenized_train = test_.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "fc1d351427b5fe27",
   "metadata": {
    "id": "fc1d351427b5fe27",
    "ExecuteTime": {
     "end_time": "2024-07-17T12:55:40.058280Z",
     "start_time": "2024-07-17T12:55:40.026786Z"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1721222486352,
     "user_tz": -120,
     "elapsed": 1038,
     "user": {
      "displayName": "Weiqi ZHANG",
      "userId": "02633163666874873570"
     }
    }
   },
   "source": [
    "# Tokenize training set and set column names to expected\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"tweets\", \"label\", \"idx\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label_id\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "6a152ef1e8f07997",
   "metadata": {
    "id": "6a152ef1e8f07997",
    "ExecuteTime": {
     "end_time": "2024-07-17T12:55:45.047428Z",
     "start_time": "2024-07-17T12:55:44.438927Z"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1721222490511,
     "user_tz": -120,
     "elapsed": 1038,
     "user": {
      "displayName": "Weiqi ZHANG",
      "userId": "02633163666874873570"
     }
    }
   },
   "source": [
    "# Prepare metrics\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    f1_metric = evaluate.load(\"f1\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='macro')\n",
    "    return {\"accuracy\": accuracy[\"accuracy\"],\"f1\": f1[\"f1\"]}"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "e319502fd5f92f57",
   "metadata": {
    "id": "e319502fd5f92f57",
    "outputId": "bbe4a9c4-a47e-49a7-ed44-28e15bbc4c5c",
    "ExecuteTime": {
     "end_time": "2024-07-17T13:05:00.381551Z",
     "start_time": "2024-07-17T13:04:57.695644Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1721223006504,
     "user_tz": -120,
     "elapsed": 594,
     "user": {
      "displayName": "Weiqi ZHANG",
      "userId": "02633163666874873570"
     }
    }
   },
   "source": [
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test-trainer\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "9c4b6d02a604f86e",
   "metadata": {
    "id": "9c4b6d02a604f86e",
    "outputId": "4881b125-feb0-4ddf-98a5-5888b32a3783",
    "ExecuteTime": {
     "end_time": "2024-07-17T13:06:17.135139Z",
     "start_time": "2024-07-17T13:05:03.870023Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1721223031008,
     "user_tz": -120,
     "elapsed": 20785,
     "user": {
      "displayName": "Weiqi ZHANG",
      "userId": "02633163666874873570"
     }
    }
   },
   "source": [
    "trainer.train()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='10275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   51/10275 00:19 < 1:06:51, 2.55 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Trainer: evaluation requires an eval_dataset.",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-3435b262f1ae>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1883\u001B[0m                 \u001B[0mhf_hub_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menable_progress_bars\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1884\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1885\u001B[0;31m             return inner_training_loop(\n\u001B[0m\u001B[1;32m   1886\u001B[0m                 \u001B[0margs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1887\u001B[0m                 \u001B[0mresume_from_checkpoint\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mresume_from_checkpoint\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001B[0m in \u001B[0;36m_inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2289\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontrol\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcallback_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_step_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontrol\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2290\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2291\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_log_save_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtr_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_norm\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrial\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mignore_keys_for_eval\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2292\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2293\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontrol\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcallback_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_substep_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontrol\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001B[0m in \u001B[0;36m_maybe_log_save_evaluate\u001B[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2719\u001B[0m         \u001B[0mmetrics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2720\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontrol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_evaluate\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2721\u001B[0;31m             \u001B[0mmetrics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mignore_keys\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mignore_keys_for_eval\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2722\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_report_to_hp_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mglobal_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2723\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001B[0m in \u001B[0;36mevaluate\u001B[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   3563\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_memory_tracker\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3564\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3565\u001B[0;31m         \u001B[0meval_dataloader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_eval_dataloader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0meval_dataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3566\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_fsdp_xla_v2_enabled\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3567\u001B[0m             \u001B[0meval_dataloader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtpu_spmd_dataloader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0meval_dataloader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001B[0m in \u001B[0;36mget_eval_dataloader\u001B[0;34m(self, eval_dataset)\u001B[0m\n\u001B[1;32m    931\u001B[0m         \"\"\"\n\u001B[1;32m    932\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0meval_dataset\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval_dataset\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 933\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Trainer: evaluation requires an eval_dataset.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    934\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    935\u001B[0m         \u001B[0;31m# If we have persistent workers, don't do a fork bomb especially as eval datasets\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Trainer: evaluation requires an eval_dataset."
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "id": "9058f56316e6ed0c"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "9058f56316e6ed0c"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
